{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "602c1b9e-16be-4470-a3a0-1f499e1019b2",
   "metadata": {},
   "source": [
    "## Sinkhorn BLOCK OT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a99f43c5-d165-4777-b6a8-0d3d2510d0c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image\n",
    "import os\n",
    "import imageio.v2 as imageio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7916f064-2c63-4deb-81eb-aecb6c3b2274",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(path, size=(128,128)):\n",
    "    img = Image.open(path).convert(\"RGB\")\n",
    "    img = img.resize(size, Image.LANCZOS)\n",
    "    return np.array(img)\n",
    "\n",
    "def save_image(array,path):\n",
    "    img = Image.fromarray(array.astype(np.uint8))\n",
    "    img.save(path)\n",
    "    print(f\"Saved : {path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "698b1064-b0b4-4561-892d-4115d5b16c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sinkhorn_transport(cost_matrix, epsilon = 0.01, n_iters=100):\n",
    "    device = cost_matrix.device\n",
    "    N = cost_matrix.shape[0]\n",
    "    a = torch.full((N,), 1.0 / N, device=device, dtype=torch.float32)\n",
    "    b = torch.full((N,), 1.0 / N, device=device, dtype=torch.float32)\n",
    "    K = torch.exp(-cost_matrix.float() / float(epsilon)).float()\n",
    "    K = torch.clamp(K, min=1e-12)\n",
    "    u = torch.ones_like(a)\n",
    "    v = torch.ones_like(b)\n",
    "    for _ in range(n_iters):\n",
    "        Kv = K @ v\n",
    "        Kv = torch.clamp(Kv, min=1e-12)\n",
    "        u = a / Kv\n",
    "        KTu = K.t() @ u\n",
    "        KTu = torch.clamp(KTu, min=1e-12)\n",
    "        v = b / KTu\n",
    "    P = (u.unsqueeze(1) * K) * v.unsqueeze(0)\n",
    "    return P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7387a22f-c36a-47d8-aa43-9bce829303a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_pixel_features(img_np, pos_weight=0.1):\n",
    "    h, w, _ = img_np.shape\n",
    "    rgb = img_np.reshape(-1, 3).astype(np.float32) / 255.0\n",
    "    ys, xs = np.meshgrid(\n",
    "        np.linspace(0, 1, h, endpoint=False),\n",
    "        np.linspace(0, 1, w, endpoint=False),\n",
    "        indexing=\"ij\"\n",
    "    )\n",
    "    xs = xs.reshape(-1, 1)\n",
    "    ys = ys.reshape(-1, 1)\n",
    "    feats = np.concatenate(\n",
    "        [rgb, pos_weight * xs, pos_weight * ys],\n",
    "        axis=1\n",
    "    )\n",
    "    return feats\n",
    "\n",
    "def compute_cost_matrix(src_feats, tgt_feats, device):\n",
    "    src = torch.from_numpy(src_feats).to(device=device, dtype=torch.float32)\n",
    "    tgt = torch.from_numpy(tgt_feats).to(device=device, dtype=torch.float32)\n",
    "    src_sq = (src ** 2).sum(dim=1, keepdim=True)     \n",
    "    tgt_sq = (tgt ** 2).sum(dim=1, keepdim=True).T   \n",
    "    cross = src @ tgt.T                              \n",
    "    cost = src_sq + tgt_sq - 2 * cross               \n",
    "    cost = torch.clamp(cost, min=0.0)\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fab3393a-46ed-4634-8940-46e7024b3700",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transport_to_permutation(P):\n",
    "    P_np = P.detach().cpu().numpy()\n",
    "    N = P_np.shape[0]\n",
    "    flat_indices = np.argsort(-P_np, axis=None)\n",
    "    used_src = np.zeros(N, dtype=bool)\n",
    "    used_tgt = np.zeros(N, dtype=bool)\n",
    "    perm = -np.ones(N, dtype=int)\n",
    "    for idx in flat_indices:\n",
    "        i = idx // N \n",
    "        j = idx % N   \n",
    "        if (not used_src[i]) and (not used_tgt[j]):\n",
    "            perm[j] = i\n",
    "            used_src[i] = True\n",
    "            used_tgt[j] = True\n",
    "        if used_tgt.all():\n",
    "            break\n",
    "    assert (perm >= 0).all(), \"Some targets were not assigned a source pixel.\"\n",
    "    return perm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e0f13010-c14f-4359-9a7d-5f295a92d9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def smooth_flow_field(flow, iters=200):\n",
    "    \"\"\"\n",
    "    Smooth a displacement field using Jacobi-like relaxation.\n",
    "\n",
    "    flow: [1, H, W, 2] tensor (dx, dy in normalized coords)\n",
    "    returns: [1, H, W, 2] smoothed tensor\n",
    "    \"\"\"\n",
    "    # Work in [N, C, H, W] layout for convenience\n",
    "    f = flow.permute(0, 3, 1, 2).clone()   # [1, 2, H, W]\n",
    "    base = f.clone()                       # original displacement, acts as anchor\n",
    "\n",
    "    for _ in range(iters):\n",
    "        # pad=(left, right, top, bottom)\n",
    "        f_pad = F.pad(f, (1, 1, 1, 1), mode=\"reflect\")\n",
    "\n",
    "        up    = f_pad[:, :, 0:-2, 1:-1]\n",
    "        down  = f_pad[:, :, 2:  , 1:-1]\n",
    "        left  = f_pad[:, :, 1:-1, 0:-2]\n",
    "        right = f_pad[:, :, 1:-1, 2:  ]\n",
    "\n",
    "        neighbor_avg = 0.25 * (up + down + left + right)\n",
    "\n",
    "        # blend neighbor-average with original flow so it doesn't collapse\n",
    "        f = 0.5 * base + 0.5 * neighbor_avg\n",
    "\n",
    "    # back to [1, H, W, 2]\n",
    "    f = f.permute(0, 2, 3, 1)\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d13f3fd3-763f-4110-abdc-c98255b1ea42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_fluid_morph_video(\n",
    "    src_np,\n",
    "    perm,\n",
    "    out_path=\"fluid_morph.mp4\",\n",
    "    n_frames=180,\n",
    "    fps=30,\n",
    "    smooth_iters=250,\n",
    "    use_gpu=True,\n",
    "    upsample_to=(128, 128)\n",
    "):\n",
    "    \"\"\"\n",
    "    src_np : [H,W,3] uint8 (here H=W=64)\n",
    "    perm   : length N permutation\n",
    "    upsample_to: final video resolution (e.g. (128,128))\n",
    "    \"\"\"\n",
    "    device = torch.device(\"cuda\" if use_gpu and torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    h, w, _ = src_np.shape\n",
    "    N = h * w\n",
    "\n",
    "    img = torch.from_numpy(src_np).float() / 255.0\n",
    "    img = img.permute(2, 0, 1).unsqueeze(0).to(device)\n",
    "\n",
    "    ys, xs = torch.meshgrid(\n",
    "        torch.arange(h, device=device, dtype=torch.float32),\n",
    "        torch.arange(w, device=device, dtype=torch.float32),\n",
    "        indexing=\"ij\"\n",
    "    )\n",
    "    x_id = 2 * xs / (w - 1) - 1\n",
    "    y_id = 2 * ys / (h - 1) - 1\n",
    "    id_grid = torch.stack([x_id, y_id], dim=-1).unsqueeze(0)\n",
    "\n",
    "    perm_t = torch.from_numpy(perm).long().to(device)\n",
    "    src_idx = torch.arange(N, device=device)\n",
    "    sy = torch.div(src_idx, w, rounding_mode=\"floor\")\n",
    "    sx = src_idx % w\n",
    "\n",
    "    y_src = sy[perm_t].view(h, w)\n",
    "    x_src = sx[perm_t].view(h, w)\n",
    "\n",
    "    xt = 2 * x_src / (w - 1) - 1\n",
    "    yt = 2 * y_src / (h - 1) - 1\n",
    "    target_grid = torch.stack([xt, yt], dim=-1).unsqueeze(0)\n",
    "\n",
    "    disp = target_grid - id_grid\n",
    "    disp_s = smooth_flow_field(disp, iters=smooth_iters)\n",
    "\n",
    "    frames = []\n",
    "\n",
    "    # --- 1) hold input frame 1 sec ---\n",
    "    hold_in_frames = int(1.0 * fps)\n",
    "    for _ in range(hold_in_frames):\n",
    "        fr = src_np.copy()\n",
    "        if upsample_to is not None:\n",
    "            fr = np.array(Image.fromarray(fr).resize(upsample_to, Image.NEAREST))\n",
    "        frames.append(fr)\n",
    "\n",
    "    # --- 2) morph ---\n",
    "    phase_split = 0.9  # 90% fluid, 10% correction\n",
    "\n",
    "    for fi in range(n_frames):\n",
    "        raw = fi / (n_frames - 1)\n",
    "        # very slow global motion\n",
    "        raw_t = (raw ** 3) ** 0.35\n",
    "\n",
    "        if raw_t < phase_split:\n",
    "            t = (raw_t / phase_split) ** 0.8\n",
    "            soft = min(1.0, raw_t * 4.0)\n",
    "            grid = id_grid + (t * soft) * disp_s\n",
    "        else:\n",
    "            k = (raw_t - phase_split) / (1 - phase_split)\n",
    "            k = k ** 1.8\n",
    "            grid_fluid_end = id_grid + disp_s\n",
    "            grid = (1 - k) * grid_fluid_end + k * target_grid\n",
    "\n",
    "        warped = F.grid_sample(\n",
    "            img, grid,\n",
    "            mode=\"bilinear\",\n",
    "            padding_mode=\"border\",\n",
    "            align_corners=True\n",
    "        )\n",
    "        fr = warped[0].permute(1, 2, 0).detach().cpu().numpy()\n",
    "        fr = np.clip(fr * 255, 0, 255).astype(np.uint8)\n",
    "        if upsample_to is not None:\n",
    "            fr = np.array(Image.fromarray(fr).resize(upsample_to, Image.NEAREST))\n",
    "        frames.append(fr)\n",
    "\n",
    "    # --- 3) hold final frame 1 sec ---\n",
    "    hold_out_frames = int(1.0 * fps)\n",
    "    src_flat = src_np.reshape(-1, 3)\n",
    "    out_flat = src_flat[perm]\n",
    "    out_final64 = out_flat.reshape(h, w, 3).astype(np.uint8)\n",
    "    if upsample_to is not None:\n",
    "        out_final = np.array(Image.fromarray(out_final64).resize(upsample_to, Image.NEAREST))\n",
    "    else:\n",
    "        out_final = out_final64\n",
    "\n",
    "    for _ in range(hold_out_frames):\n",
    "        frames.append(out_final.copy())\n",
    "\n",
    "    # --- save MP4 ---\n",
    "    writer = imageio.get_writer(\n",
    "        out_path,\n",
    "        fps=fps,\n",
    "        codec=\"libx264\",\n",
    "        format=\"ffmpeg\",\n",
    "        quality=8,\n",
    "        pixelformat=\"yuv420p\"\n",
    "    )\n",
    "    for fr in frames:\n",
    "        writer.append_data(fr)\n",
    "    writer.close()\n",
    "    print(\"Saved video:\", out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "25b7eaec-bd82-494d-8673-1dcb33b70934",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_patches_indices(h, w, patch_size):\n",
    "    \"\"\"\n",
    "    Split an HxW image into patches of size patch_size x patch_size.\n",
    "    Returns:\n",
    "        patch_indices: list of 1D numpy arrays of pixel indices (flattened index)\n",
    "    \"\"\"\n",
    "    patch_indices = []\n",
    "    for y0 in range(0, h, patch_size):\n",
    "        for x0 in range(0, w, patch_size):\n",
    "            ys, xs = np.meshgrid(\n",
    "                np.arange(y0, min(y0 + patch_size, h)),\n",
    "                np.arange(x0, min(x0 + patch_size, w)),\n",
    "                indexing=\"ij\"\n",
    "            )\n",
    "            idxs = ys * w + xs  # flatten index\n",
    "            patch_indices.append(idxs.reshape(-1))\n",
    "    return patch_indices  # length = (h/ps)*(w/ps) if divisible\n",
    "\n",
    "\n",
    "def patch_centroids(feats_np, patch_indices):\n",
    "    \"\"\"\n",
    "    Compute the centroid (mean feature) of each patch.\n",
    "    feats_np: [N, D] numpy\n",
    "    patch_indices: list of arrays of indices\n",
    "    Returns:\n",
    "        centroids: [M, D] numpy\n",
    "    \"\"\"\n",
    "    D = feats_np.shape[1]\n",
    "    M = len(patch_indices)\n",
    "    centroids = np.zeros((M, D), dtype=np.float32)\n",
    "    for i, idxs in enumerate(patch_indices):\n",
    "        centroids[i] = feats_np[idxs].mean(axis=0)\n",
    "    return centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a83995e5-b2f9-4ac4-bdfc-bf1b0777cdec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_scale_ot_permutation(\n",
    "    src128_np,\n",
    "    tgt128_np,\n",
    "    pos_weight=0.1,\n",
    "    coarse_size=32,\n",
    "    epsilon_coarse=0.02,\n",
    "    n_iters_coarse=80,\n",
    "    use_gpu=True\n",
    "):\n",
    "    \"\"\"\n",
    "    Improved multi-scale OT without block artifacts.\n",
    "\n",
    "    Idea:\n",
    "      1. Downsample both images to coarse_size x coarse_size (e.g. 32x32).\n",
    "      2. Run full Sinkhorn OT at coarse resolution.\n",
    "      3. Compute a barycentric target position for each coarse *source* pixel.\n",
    "      4. Propagate that mapping to 128x128 by assigning each high-res pixel\n",
    "         the barycentric coord of its coarse cell.\n",
    "      5. Turn those continuous target coords into a global permutation\n",
    "         by sorting source pixels by their barycentric position and matching\n",
    "         them to the regular 128x128 grid order.\n",
    "\n",
    "    Returns:\n",
    "        perm128: length (128*128) permutation, perm[j] = source index\n",
    "                 for target index j.\n",
    "    \"\"\"\n",
    "    device = torch.device(\"cuda\" if use_gpu and torch.cuda.is_available() else \"cpu\")\n",
    "    H, W, _ = src128_np.shape\n",
    "    assert H == 128 and W == 128, \"Assumes 128x128 images.\"\n",
    "\n",
    "    # ---------- 1. Coarse images ----------\n",
    "    src32_np = np.array(Image.fromarray(src128_np).resize((coarse_size, coarse_size), Image.LANCZOS))\n",
    "    tgt32_np = np.array(Image.fromarray(tgt128_np).resize((coarse_size, coarse_size), Image.LANCZOS))\n",
    "\n",
    "    src32_feats = build_pixel_features(src32_np, pos_weight=pos_weight)  # [Nc, 5]\n",
    "    tgt32_feats = build_pixel_features(tgt32_np, pos_weight=pos_weight)\n",
    "\n",
    "    Nc = coarse_size * coarse_size\n",
    "    print(f\"Coarse OT at {coarse_size}x{coarse_size} ({Nc} pixels)…\")\n",
    "\n",
    "    # ---------- 2. Coarse OT ----------\n",
    "    cost_coarse = compute_cost_matrix(src32_feats, tgt32_feats, device=device)\n",
    "    P_coarse = sinkhorn_transport(cost_coarse, epsilon=epsilon_coarse, n_iters=n_iters_coarse)  # [Nc, Nc]\n",
    "\n",
    "    # ---------- 3. Barycentric target coords for each coarse SOURCE pixel ----------\n",
    "    # Build coarse target coords in [0,1]x[0,1]\n",
    "    ys_c, xs_c = np.meshgrid(\n",
    "        np.linspace(0.0, 1.0, coarse_size, endpoint=False),\n",
    "        np.linspace(0.0, 1.0, coarse_size, endpoint=False),\n",
    "        indexing=\"ij\"\n",
    "    )\n",
    "    coords_c = np.stack([ys_c.reshape(-1), xs_c.reshape(-1)], axis=1).astype(np.float32)  # [Nc, 2]\n",
    "    coords_c_t = torch.from_numpy(coords_c).to(device=device)\n",
    "\n",
    "    # Normalize rows of P_coarse → barycentric weights\n",
    "    row_sums = P_coarse.sum(dim=1, keepdim=True)            # [Nc,1]\n",
    "    weights = P_coarse / torch.clamp(row_sums, min=1e-8)    # [Nc,Nc]\n",
    "\n",
    "    # Barycentric target coord for each coarse source pixel\n",
    "    bary_src = weights @ coords_c_t                         # [Nc, 2]\n",
    "\n",
    "    # ---------- 4. Lift mapping to 128x128 ----------\n",
    "    block = H // coarse_size                                # 128/32 = 4\n",
    "    ys_hi, xs_hi = np.meshgrid(np.arange(H), np.arange(W), indexing=\"ij\")\n",
    "    cy = ys_hi // block                                     # coarse y\n",
    "    cx = xs_hi // block                                     # coarse x\n",
    "    coarse_index = (cy * coarse_size + cx).reshape(-1)      # [N]\n",
    "\n",
    "    # For each high-res source pixel, assign bary coords of its coarse cell\n",
    "    bary_hi = bary_src[coarse_index].detach().cpu().numpy()  # [N, 2]\n",
    "\n",
    "    # Convert barycentric coords to continuous [0,H]x[0,W] positions\n",
    "    tY = bary_hi[:, 0] * (H - 1)    # [N]\n",
    "    tX = bary_hi[:, 1] * (W - 1)    # [N]\n",
    "\n",
    "    # ---------- 5. Build a global permutation by sorting ----------\n",
    "    N = H * W\n",
    "    src_indices = np.arange(N, dtype=np.int64)\n",
    "\n",
    "    # Key for sorting: y*W + x in continuous space\n",
    "    src_keys = tY * W + tX          # [N]\n",
    "\n",
    "    # Target grid is already in row-major order 0..N-1\n",
    "    tgt_indices = np.arange(N, dtype=np.int64)\n",
    "\n",
    "    # Sort both\n",
    "    src_sorted = np.argsort(src_keys)\n",
    "    tgt_sorted = tgt_indices        # already sorted, but keep for clarity\n",
    "\n",
    "    perm128 = np.empty(N, dtype=np.int64)\n",
    "    # Match kth sorted source → kth target\n",
    "    perm128[tgt_sorted] = src_indices[src_sorted]\n",
    "\n",
    "    return perm128\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7ffeea03-9990-49e6-a33f-eb13264019bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_image_to_target(\n",
    "    input_path,\n",
    "    target_path,\n",
    "    out_path=\"output_modi_128.png\",\n",
    "    video_path=\"fluid_morph_128.mp4\",\n",
    "    work_size=(64, 64),\n",
    "    out_size=(128, 128),\n",
    "    pos_weight=0.3,\n",
    "    use_gpu=True\n",
    "):\n",
    "    # load at working resolution\n",
    "    src = load_image(input_path, size=work_size)\n",
    "    tgt = load_image(target_path, size=work_size)\n",
    "\n",
    "    # OT at 64×64\n",
    "    device = torch.device(\"cuda\" if use_gpu and torch.cuda.is_available() else \"cpu\")\n",
    "    src_feats = build_pixel_features(src, pos_weight=pos_weight)\n",
    "    tgt_feats = build_pixel_features(tgt, pos_weight=pos_weight)\n",
    "\n",
    "    print(\"Computing cost matrix at\", work_size, \"…\")\n",
    "    cost = compute_cost_matrix(src_feats, tgt_feats, device=device)\n",
    "    print(\"Running Sinkhorn OT…\")\n",
    "    P = sinkhorn_transport(cost, epsilon=0.01, n_iters=150)\n",
    "    perm = transport_to_permutation(P)\n",
    "\n",
    "    # static result at 64×64, then upscale to 128×128\n",
    "    flat = src.reshape(-1, 3)\n",
    "    out_flat = flat[perm]\n",
    "    out64 = out_flat.reshape(work_size[1], work_size[0], 3)\n",
    "    out128 = np.array(Image.fromarray(out64.astype(np.uint8)).resize(out_size, Image.NEAREST))\n",
    "    save_image(out128, out_path)\n",
    "\n",
    "    # fluid morph video, directly writing 128×128 frames\n",
    "    create_fluid_morph_video(\n",
    "        src_np=src,\n",
    "        perm=perm,\n",
    "        out_path=video_path,\n",
    "        n_frames=180,\n",
    "        fps=30,\n",
    "        smooth_iters=250,\n",
    "        use_gpu=use_gpu,\n",
    "        upsample_to=out_size\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8733fba7-c79b-48d5-98b2-e5f13a15c1d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing cost matrix at (128, 128) …\n",
      "Running Sinkhorn OT…\n",
      "Saved : C:\\Users\\vaibh\\Downloads\\output_modi_multiscale.png\n",
      "Saved video: C:\\Users\\vaibh\\Downloads\\morph_to_modi_multiscale.mp4\n"
     ]
    }
   ],
   "source": [
    "inp = r\"C:\\Users\\vaibh\\Downloads\\Image_created_with_a_mobile_phone.png\"\n",
    "out = r\"C:\\Users\\vaibh\\Downloads\\WhatsApp Image 2025-11-16 at 15.12.38_1ce65b8f.jpg\"\n",
    "\n",
    "transform_image_to_target(\n",
    "        input_path=inp,\n",
    "        target_path=out,\n",
    "        out_path=r\"C:\\Users\\vaibh\\Downloads\\output_modi_multiscale.png\",\n",
    "        video_path=r\"C:\\Users\\vaibh\\Downloads\\morph_to_modi_multiscale.mp4\",\n",
    "        work_size=(128, 128),    # internal OT resolution\n",
    "    out_size=(128, 128),   # final image / video size\n",
    "    pos_weight=0.3,\n",
    "    use_gpu=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bff368e-64c8-4407-9ab7-d0cd4a96e07d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
